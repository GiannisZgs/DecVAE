{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e12c7440",
   "metadata": {},
   "source": [
    "# DecVAE Tutorial: IEMOCAP Dataset\n",
    "\n",
    "Complete workflow example for the IEMOCAP dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2028ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the working directory to the DecVAE root\n",
    "# Adjust this path to your local DecVAE directory\n",
    "DECVAE_ROOT = Path(os.getcwd()).parent if 'examples' in os.getcwd() else Path(os.getcwd())\n",
    "os.chdir(DECVAE_ROOT)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8de2bf7",
   "metadata": {},
   "source": [
    "## 1. Prepare IEMOCAP Dataset\n",
    "\n",
    "The IEMOCAP (Interactive Emotional Dyadic Motion Capture) dataset contains emotional speech recordings.\n",
    "\n",
    "Download from: [https://sail.usc.edu/iemocap/](https://sail.usc.edu/iemocap/)\n",
    "\n",
    "After downloading, place the dataset in \"../IEMOCAP\" (same level as the DecVAE project directory)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee853816",
   "metadata": {},
   "source": [
    "## 2. Input Visualization\n",
    "\n",
    "We generate input visualizations for the raw audio signal (X), and the components after applying a decomposition. We visualize individual components (OC1, OC2, ..., OCn) and aggregated representations, e.g. concatenation of all components and initial X [X,OC1,OC2,...,OCn]. We color the representations using frequency correspondence of the inputs or generative factors (phoneme, speaker, emotion).\n",
    "\n",
    "For the IEMOCAP dataset, we will visualize the inputs to all models.\n",
    "\n",
    "Frame-level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e944732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize frame-level inputs\n",
    "!accelerate launch scripts/visualize/low_dim_vis_input.py \\\n",
    "    --config_file config_files/input_visualizations/config_visualizing_input_frames_iemocap.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba20cfb",
   "metadata": {},
   "source": [
    "Sequence-level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sequence-level inputs\n",
    "!accelerate launch scripts/visualize/low_dim_vis_input.py \\\n",
    "    --config_file config_files/input_visualizations/config_visualizing_input_sequences_iemocap.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37336e6b",
   "metadata": {},
   "source": [
    "## 3. Fine-tuning DecVAE\n",
    "\n",
    "For IEMOCAP, we use fine-tuning on a pre-trained model rather than training from scratch.\n",
    "\n",
    "Single-GPU: use the --gpu_ids argument to specify the id of the GPU (0,1,2,...) - accelerate launch --gpu_ids <id> scripts... . Alternatively omit this argument and the default GPU id in your system will be used (as below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51307f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune DecVAE on single GPU\n",
    "!accelerate launch scripts/fine_tuning/ssl_fine_tune_pretrained_models.py \\\n",
    "    --config_file config_files/DecVAEs/iemocap/fine_tuning/config_finetune_iemocap_NoC4.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465945eb",
   "metadata": {},
   "source": [
    "Multi-GPU (specify GPU IDs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c96ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune DecVAE on multiple GPUs (e.g., GPU 0 and 1)\n",
    "# Uncomment and modify as needed:\n",
    "# !accelerate launch --gpu_ids 0,1 scripts/fine_tuning/ssl_fine_tune_pretrained_models.py \\\n",
    "#     --config_file config_files/DecVAEs/iemocap/fine_tuning/config_finetune_iemocap_NoC4.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adadc967",
   "metadata": {},
   "source": [
    "View configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb012593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"config_files/DecVAEs/iemocap/fine_tuning/config_finetune_iemocap_NoC4.json\", 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dbbc9c",
   "metadata": {},
   "source": [
    "## 4. Latent Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02091d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate latent representations\n",
    "!accelerate launch scripts/post-training/latents_post_analysis.py \\\n",
    "    --config_file config_files/DecVAEs/iemocap/latent_evaluations/config_latent_anal_iemocap.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d6cc12",
   "metadata": {},
   "source": [
    "## 5. Latent Visualization\n",
    "\n",
    "Frame-level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e80b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize frame-level latent representations\n",
    "!accelerate launch scripts/visualize/low_dim_vis_latents.py \\\n",
    "    --config_file config_files/DecVAEs/iemocap/latent_visualizations/config_latent_frames_visualization_iemocap.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4075b0",
   "metadata": {},
   "source": [
    "Sequence-level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc379d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sequence-level latent representations\n",
    "!accelerate launch scripts/visualize/low_dim_vis_latents.py \\\n",
    "    --config_file config_files/DecVAEs/iemocap/latent_visualizations/config_latent_sequences_visualization_iemocap.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b05806",
   "metadata": {},
   "source": [
    "## 6. Latent Traversals\n",
    "\n",
    "Perform traversal analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb11e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform latent traversal analysis\n",
    "!accelerate launch scripts/latent_response_analysis/latent_traversal_analysis.py \\\n",
    "    --config_file config_files/DecVAEs/iemocap/latent_traversals/config_latent_traversals_iemocap.json"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
